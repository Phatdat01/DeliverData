version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
    networks:
      - data_network
  
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_network
  
  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    volumes:
      - ./minio/data:/data
    env_file:
      - .env
    networks:
      - data_network

  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore"
    entrypoint: /entrypoint.sh
    ports:
      - "9083:9083"
    volumes:
      # - ./hive-metastore/entrypoint.sh:/entrypoint.sh
      - ./hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: de_mysql
    networks:
      - data_network
    depends_on:
      - de_mysql
      - minio
    
  de_mysql:
    image: mariadb:10.11.2
    container_name: de_mysql
    ports:
      - "3306:3306"
    env_file:
      - .env
    networks:
      - data_network

  spark-master:
    build:
      context: ./spark
      dockerfile: ./Dockerfile
    container_name: "spark-master"
    ports:
      - "7077:7077"  # Spark master port
      - "8081:8080"  # Spark master web UI port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - data_network

  spark-worker-1:
    image: docker.io/bitnami/spark:3.3
    container_name: "spark-worker-1"
    env_file:
      - .env
    depends_on:
      - spark-master
    networks:
      - data_network

  spark-worker-2:
    image: docker.io/bitnami/spark:3.3
    container_name: "spark-worker-2"
    env_file:
      - .env
    depends_on:
      - spark-master
    networks:
      - data_network

  spark-thrift-server:
    build:
      context: ./spark
      dockerfile: ./Dockerfile
    container_name: "spark-thrift-server"
    restart: always
    depends_on:
      - spark-master
      - hive-metastore
    ports:
      - "4040:4040"
      - "10000:10000"
    command: sh -c "
      sleep 10 && ./sbin/start-thriftserver.sh --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083' --master spark://spark-master:7077      --executor-memory 4G --total-executor-cores 4 --driver-memory 4G"
    volumes:
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    networks:
      - data_network

networks:
  data_network:
    driver: bridge
    name: data_network